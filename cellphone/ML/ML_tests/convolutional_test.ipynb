{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import barabasi_albert_graph\n",
    "from torch_geometric.transforms import LaplacianLambdaMax\n",
    "from torch_geometric_temporal.nn.convolutional import TemporalConv, STConv, ASTGCN, MSTGCN, MTGNN, ChebConvAttention\n",
    "from torch_geometric_temporal.nn.convolutional import GMAN, SpatioTemporalAttention, SpatioTemporalEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mock_data(number_of_nodes, edge_per_node, in_channels):\n",
    "    \"\"\"\n",
    "    Creating a mock feature matrix and edge index.\n",
    "    \"\"\"\n",
    "    graph = nx.watts_strogatz_graph(number_of_nodes, edge_per_node, 0.5)\n",
    "    edge_index = torch.LongTensor(np.array([edge for edge in graph.edges()]).T)\n",
    "    X = torch.FloatTensor(np.random.uniform(-1, 1, (number_of_nodes, in_channels)))\n",
    "    return X, edge_index\n",
    "\n",
    "def create_mock_edge_weight(edge_index):\n",
    "    \"\"\"\n",
    "    Creating a mock edge weight tensor.\n",
    "    \"\"\"\n",
    "    return torch.FloatTensor(np.random.uniform(0, 1, (edge_index.shape[1])))\n",
    "\n",
    "def create_mock_target(number_of_nodes, number_of_classes):\n",
    "    \"\"\"\n",
    "    Creating a mock target vector.\n",
    "    \"\"\"\n",
    "    return torch.LongTensor([np.random.randint(0, number_of_classes-1) for node in range(number_of_nodes)])\n",
    "\n",
    "def create_mock_sequence(sequence_length, number_of_nodes, edge_per_node, in_channels, number_of_classes):\n",
    "    \"\"\"\n",
    "    Creating mock sequence data\n",
    "    \n",
    "    Note that this is a static graph discrete signal type sequence\n",
    "    The target is the \"next\" item in the sequence\n",
    "    \"\"\"\n",
    "    input_sequence = torch.zeros(sequence_length, number_of_nodes, in_channels)\n",
    "    \n",
    "    X, edge_index = create_mock_data(number_of_nodes=number_of_nodes, edge_per_node=edge_per_node, in_channels=in_channels)\n",
    "    edge_weight = create_mock_edge_weight(edge_index)\n",
    "    targets = create_mock_target(number_of_nodes, number_of_classes)\n",
    "\n",
    "    for t in range(sequence_length):\n",
    "        input_sequence[t] = X+t\n",
    "\n",
    "    return input_sequence, targets, edge_index, edge_weight\n",
    "\n",
    "def create_mock_batch(batch_size, sequence_length, number_of_nodes, edge_per_node, in_channels, number_of_classes):\n",
    "    \"\"\"\n",
    "    Creating a mock batch of sequences\n",
    "    \"\"\"\n",
    "    batch = torch.zeros(batch_size, sequence_length, number_of_nodes, in_channels)\n",
    "    batch_targets = torch.zeros(batch_size, number_of_nodes, dtype=torch.long)\n",
    "    \n",
    "    for b in range(batch_size):\n",
    "        input_sequence, targets, edge_index, edge_weight = create_mock_sequence(sequence_length, number_of_nodes, edge_per_node, in_channels, number_of_classes)\n",
    "        batch[b] = input_sequence\n",
    "        batch_targets[b] = targets\n",
    "\n",
    "    return batch, batch_targets, edge_index, edge_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Testing MSTGCN block with changing edge index over time.\n",
    "\"\"\"\n",
    "node_count = 307\n",
    "num_classes = 10\n",
    "edge_per_node = 15\n",
    "\n",
    "num_for_predict = 12\n",
    "len_input = 12\n",
    "nb_time_strides = 1\n",
    "\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "node_features = 2\n",
    "nb_block = 2\n",
    "K = 3\n",
    "nb_chev_filter = 64\n",
    "nb_time_filter = 64\n",
    "batch_size = 1\n",
    "\n",
    "model = MSTGCN( nb_block, node_features, K, nb_chev_filter,\n",
    "                nb_time_filter, nb_time_strides, \n",
    "                num_for_predict, len_input ).to(device)\n",
    "T = len_input\n",
    "x_seq = torch.zeros([batch_size,node_count, node_features,T]).to(device)\n",
    "target_seq = torch.zeros([batch_size,node_count,T]).to(device)\n",
    "edge_index_seq = []\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(T):\n",
    "        x, edge_index = create_mock_data(node_count, 2*(t+1), node_features)\n",
    "        #print(x.shape, edge_index.shape)\n",
    "        x_seq[b,:,:,t] = x.to(device)\n",
    "        #if b == 0:\n",
    "        edge_index_seq.append( edge_index.to(device) )\n",
    "        target = create_mock_target(node_count, num_classes).to(device)\n",
    "        target_seq[b,:,t] = target\n",
    "\n",
    "shuffle = True\n",
    "#print(x_seq.shape, target_seq.shape, len(edge_index_seq) )\n",
    "train_dataset = torch.utils.data.TensorDataset( x_seq, target_seq )\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "for batch_data in train_loader:\n",
    "    encoder_inputs, _ = batch_data\n",
    "    outputs1 = model(encoder_inputs, edge_index_seq)\n",
    "    outputs2 = model(encoder_inputs, edge_index_seq[0])\n",
    "\n",
    "assert outputs1.shape == (batch_size, node_count, num_for_predict)\n",
    "assert outputs2.shape == (batch_size, node_count, num_for_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 307, 2, 12]) torch.Size([1, 307, 12]) 12\n"
     ]
    }
   ],
   "source": [
    "print(x_seq.shape, target_seq.shape, len(edge_index_seq) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.float32, torch.int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_seq.dtype, target_seq.dtype, edge_index_seq[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.8175,  0.6724,  1.0434,  ..., -0.9552,  0.8803,  0.2471],\n",
       "         [-0.8206,  0.2323,  0.9486,  ..., -0.9708,  0.7109,  0.4421],\n",
       "         [-0.8519,  0.3284,  0.9682,  ..., -0.6460,  0.9835,  0.1755],\n",
       "         ...,\n",
       "         [-1.1424,  0.5672,  1.1176,  ..., -1.2706,  0.5072,  0.9132],\n",
       "         [-0.7091,  0.6109,  1.1609,  ..., -1.4413,  0.9390,  0.6822],\n",
       "         [-0.9816,  0.7417,  1.0512,  ..., -1.3903,  0.6515,  0.8488]]],\n",
       "       grad_fn=<PermuteBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model( x_seq, edge_index_seq )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9215,  0.4003,  1.0774,  ..., -0.6848,  0.9072,  0.3584],\n",
       "         [-0.9199,  0.1810,  1.1363,  ..., -0.9495,  0.8687,  0.4297],\n",
       "         [-0.8190,  0.2504,  1.0142,  ..., -0.5723,  0.8829,  0.3445],\n",
       "         ...,\n",
       "         [-0.8948,  0.4124,  0.5023,  ..., -0.7351,  0.7836, -0.1730],\n",
       "         [-0.7876,  0.4367,  0.6315,  ..., -1.2420,  0.8399,  0.3512],\n",
       "         [-0.7813,  0.5204,  0.4176,  ..., -0.9701,  0.7676,  0.3758]]],\n",
       "       grad_fn=<PermuteBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model( x_seq, edge_index_seq[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index_seq[0].dtype"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Testing ASTGCN block and its component ChebConvAttention with changing edge index over time or not\n",
    "\"\"\"\n",
    "\n",
    "in_channels, out_channels = (16, 32)\n",
    "batch_size = 3\n",
    "edge_index = torch.tensor([[0, 0, 0, 1, 2, 3], [1, 2, 3, 0, 0, 0]]).to(device)\n",
    "num_nodes = edge_index.max().item() + 1\n",
    "edge_weight = torch.rand(edge_index.size(1)).to(device)\n",
    "x = torch.randn((batch_size, num_nodes, in_channels)).to(device)\n",
    "attention = torch.nn.functional.softmax(torch.rand((batch_size, num_nodes, num_nodes)), dim=1).to(device)\n",
    "\n",
    "conv = ChebConvAttention(in_channels, out_channels, K=3, normalization='sym').to(device)\n",
    "assert conv.__repr__() == 'ChebConvAttention(16, 32, K=3, normalization=sym)'\n",
    "out1 = conv(x, edge_index, attention)\n",
    "assert out1.size() == (batch_size, num_nodes, out_channels)\n",
    "out2 = conv(x, edge_index, attention, edge_weight)\n",
    "assert out2.size() == (batch_size, num_nodes, out_channels)\n",
    "out3 = conv(x, edge_index, attention, edge_weight, lambda_max=3.0)\n",
    "assert out3.size() == (batch_size, num_nodes, out_channels)\n",
    "\n",
    "batch = torch.tensor([0, 0, 1, 1]).to(device)\n",
    "edge_index = torch.tensor([[0, 1, 2, 3], [1, 0, 3, 2]]).to(device)\n",
    "num_nodes = edge_index.max().item() + 1\n",
    "edge_weight = torch.rand(edge_index.size(1)).to(device)\n",
    "x = torch.randn((batch_size, num_nodes, in_channels)).to(device)\n",
    "lambda_max = torch.tensor([2.0, 3.0]).to(device)\n",
    "attention = torch.nn.functional.softmax(torch.rand((batch_size, num_nodes, num_nodes)), dim=1).to(device)\n",
    "\n",
    "out4 = conv(x, edge_index, attention, edge_weight, batch)\n",
    "assert out4.size() == (batch_size, num_nodes, out_channels)\n",
    "out5 = conv(x, edge_index, attention, edge_weight, batch, lambda_max)\n",
    "assert out5.size() == (batch_size, num_nodes, out_channels)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device('cpu')\n",
    "\n",
    "node_count = 307\n",
    "num_classes = 10\n",
    "edge_per_node = 15\n",
    "\n",
    "num_for_predict = 12\n",
    "len_input = 12\n",
    "nb_time_strides = 1\n",
    "\n",
    "\n",
    "node_features = 2\n",
    "nb_block = 2\n",
    "K = 3\n",
    "nb_chev_filter = 64\n",
    "nb_time_filter = 64\n",
    "batch_size = 1\n",
    "normalization = None\n",
    "bias = True\n",
    "\n",
    "model = ASTGCN(nb_block, node_features, K, nb_chev_filter, nb_time_filter, nb_time_strides, num_for_predict, \n",
    "        len_input, node_count, normalization, bias).to(device)\n",
    "model2 = ASTGCN(nb_block, node_features, K, nb_chev_filter, nb_time_filter, nb_time_strides, num_for_predict, \n",
    "        len_input, node_count, 'sym', False).to(device)\n",
    "model3 = ASTGCN(nb_block, node_features, K, nb_chev_filter, nb_time_filter, nb_time_strides, num_for_predict, \n",
    "        len_input, node_count, 'rw', bias).to(device)\n",
    "T = len_input\n",
    "\n",
    "\"\"\"\n",
    "x_seq = torch.zeros([batch_size,node_count, node_features,T]).to(device)\n",
    "target_seq = torch.zeros([batch_size,node_count,T]).to(device)\n",
    "edge_index_seq = []\n",
    "for b in range(batch_size):\n",
    "    for t in range(T):\n",
    "        x, edge_index = create_mock_data(node_count, 2*(t+1), node_features)\n",
    "        x_seq[b,:,:,t] = x.to(device)\n",
    "        #if b == 0:\n",
    "        edge_index_seq.append(edge_index.to(device))\n",
    "        target = create_mock_target(node_count, num_classes).to(device)\n",
    "        target_seq[b,:,t] = target\n",
    "shuffle = True\n",
    "train_dataset = torch.utils.data.TensorDataset(x_seq, target_seq)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "for batch_data in train_loader:\n",
    "    encoder_inputs, _ = batch_data\n",
    "    outputs0 = model(encoder_inputs, edge_index_seq)\n",
    "    outputs1 = model(encoder_inputs, edge_index_seq[0])\n",
    "    outputs2 = model2(encoder_inputs, edge_index_seq[0])\n",
    "    outputs3 = model2(encoder_inputs, edge_index_seq)\n",
    "    outputs4 = model3(encoder_inputs, edge_index_seq[0])\n",
    "    outputs5 = model3(encoder_inputs, edge_index_seq)\n",
    "assert outputs0.shape == (batch_size, node_count, num_for_predict)\n",
    "assert outputs1.shape == (batch_size, node_count, num_for_predict)\n",
    "assert outputs2.shape == (batch_size, node_count, num_for_predict)\n",
    "assert outputs3.shape == (batch_size, node_count, num_for_predict)\n",
    "assert outputs4.shape == (batch_size, node_count, num_for_predict)\n",
    "assert outputs5.shape == (batch_size, node_count, num_for_predict)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([307, 2, 12]), 12, torch.Size([2, 307]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_seq[0].shape, len( edge_index_seq ), edge_index_seq[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.9647, -0.9167,  0.7907, -0.0637, -0.8508, -0.9583, -0.7610, -0.8589,\n",
       "          -0.2375,  0.2733, -0.5891, -0.7227],\n",
       "         [-0.9545, -0.6329, -0.4435, -0.4049,  0.5680,  0.8029,  0.7929,  0.3561,\n",
       "           0.2712, -0.6077, -0.8194, -0.1498]]),\n",
       " [tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   7,   8,   9,  10,  11,  12,\n",
       "            13,  13,  14,  14,  14,  15,  15,  16,  17,  18,  19,  20,  21,  22,\n",
       "            22,  23,  23,  24,  24,  25,  26,  27,  27,  27,  27,  28,  28,  29,\n",
       "            30,  31,  32,  32,  33,  34,  34,  35,  35,  36,  36,  37,  38,  38,\n",
       "            39,  40,  41,  41,  42,  43,  44,  45,  45,  46,  47,  48,  48,  48,\n",
       "            49,  49,  50,  51,  52,  53,  53,  53,  54,  54,  55,  55,  56,  57,\n",
       "            58,  60,  61,  62,  62,  63,  64,  65,  65,  66,  66,  68,  69,  69,\n",
       "            70,  70,  71,  72,  74,  75,  75,  76,  76,  77,  77,  78,  79,  80,\n",
       "            81,  81,  83,  84,  84,  85,  86,  87,  88,  89,  90,  91,  91,  91,\n",
       "            93,  93,  94,  95,  95,  96,  99, 100, 101, 102, 105, 105, 106, 106,\n",
       "           107, 108, 108, 109, 110, 111, 113, 113, 114, 115, 116, 116, 118, 119,\n",
       "           120, 120, 121, 121, 121, 122, 123, 123, 124, 125, 127, 127, 128, 129,\n",
       "           129, 130, 131, 131, 132, 132, 132, 134, 137, 137, 139, 139, 142, 143,\n",
       "           144, 145, 146, 147, 148, 149, 150, 152, 156, 157, 157, 158, 159, 159,\n",
       "           160, 161, 164, 165, 166, 167, 169, 170, 171, 172, 173, 174, 175, 177,\n",
       "           178, 178, 179, 180, 181, 182, 184, 185, 188, 188, 189, 190, 191, 192,\n",
       "           192, 195, 196, 197, 201, 203, 205, 205, 206, 207, 208, 208, 209, 214,\n",
       "           215, 218, 219, 220, 221, 222, 223, 225, 226, 227, 229, 230, 231, 231,\n",
       "           232, 233, 234, 235, 236, 237, 238, 240, 242, 243, 244, 245, 247, 248,\n",
       "           249, 250, 251, 253, 254, 255, 256, 258, 259, 263, 265, 267, 269, 270,\n",
       "           272, 273, 274, 276, 277, 277, 278, 282, 283, 284, 286, 287, 288, 288,\n",
       "           289, 290, 292, 293, 294, 295, 296, 297, 300, 301, 302, 303, 305],\n",
       "          [  1, 106,   3,   4,   5,   6,  22, 174, 220,   9, 127,  67, 108, 291,\n",
       "           108, 151,  15, 104, 268,  16,  98,  17,  18, 174,  20,  21, 199,  97,\n",
       "           117, 220, 168,  25, 136, 161,  27,  28,  92, 111, 271,  29,  73, 223,\n",
       "            31,  38,  33, 141,  34,  35, 187,  42, 133,  94, 125,  41,  65, 281,\n",
       "            40,  41,  42, 219, 144,  44,  45,  46, 246,  47, 114, 269,  60, 275,\n",
       "           172, 112, 280, 280, 230,  54,  59,  75, 163,  67, 209,  97,  57,  58,\n",
       "            59, 103,  62, 166, 198,  64,  67, 303, 162, 125, 241, 301, 162, 210,\n",
       "            71, 204,  72,  73,  75,  82, 258,  77, 155,  78, 186, 294,  80, 136,\n",
       "           125, 126, 186,  85, 212,  86, 200,  88,  89,  90,  91, 114, 172, 203,\n",
       "           245, 298, 244,  96, 183,  97, 100, 213, 102, 120, 232, 193, 107, 232,\n",
       "           108, 281, 134, 110, 285, 149, 114, 135, 115, 116, 253, 163, 119, 144,\n",
       "           121, 154, 122, 140, 264, 123, 190, 202, 125, 257, 128, 176, 129, 130,\n",
       "           217, 179, 132, 279, 133, 153, 280, 138, 138, 266, 140, 224, 143, 144,\n",
       "           217, 146, 190, 201, 149, 161, 198, 153, 157, 158, 299, 234, 160, 200,\n",
       "           161, 213, 165, 243, 167, 168, 260, 171, 172, 199, 174, 175, 183, 178,\n",
       "           304, 194, 245, 209, 284, 183, 185, 186, 191, 262, 190, 234, 192, 193,\n",
       "           211, 196, 262, 198, 202, 304, 206, 216, 287, 224, 209, 252, 210, 215,\n",
       "           216, 219, 228, 285, 222, 223, 241, 272, 230, 228, 230, 231, 232, 239,\n",
       "           260, 234, 235, 236, 237, 238, 239, 241, 243, 244, 245, 281, 248, 249,\n",
       "           250, 251, 279, 254, 255, 299, 257, 261, 260, 264, 266, 268, 270, 271,\n",
       "           273, 274, 278, 296, 278, 291, 279, 283, 284, 301, 287, 288, 289, 306,\n",
       "           290, 291, 293, 294, 295, 296, 297, 298, 303, 302, 303, 304, 306]]),\n",
       "  tensor([[  0,   0,   0,  ..., 299, 302, 304],\n",
       "          [  2,  14,   1,  ..., 301, 303, 306]]),\n",
       "  tensor([[  0,   0,   0,  ..., 303, 303, 303],\n",
       "          [306,   2, 305,  ..., 304, 305, 306]]),\n",
       "  tensor([[  0,   0,   0,  ..., 303, 303, 305],\n",
       "          [306,   2, 305,  ..., 305, 306, 306]]),\n",
       "  tensor([[  0,   0,   0,  ..., 302, 303, 305],\n",
       "          [  3, 304,   5,  ..., 304, 304, 306]]),\n",
       "  tensor([[  0,   0,   0,  ..., 302, 303, 305],\n",
       "          [306,   2, 305,  ..., 305, 306, 306]]),\n",
       "  tensor([[  0,   0,   0,  ..., 304, 304, 305],\n",
       "          [  1, 306, 305,  ..., 305, 306, 306]]),\n",
       "  tensor([[  0,   0,   0,  ..., 303, 304, 304],\n",
       "          [  2, 305,   3,  ..., 304, 305, 306]]),\n",
       "  tensor([[  0,   0,   0,  ..., 302, 303, 305],\n",
       "          [  2, 305, 304,  ..., 305, 306, 306]]),\n",
       "  tensor([[  0,   0,   0,  ..., 302, 303, 304],\n",
       "          [  1, 306, 305,  ..., 304, 306, 305]]),\n",
       "  tensor([[  0,   0,   0,  ..., 303, 303, 304],\n",
       "          [  1, 306,   2,  ..., 305, 306, 305]]),\n",
       "  tensor([[  0,   0,   0,  ..., 302, 303, 303],\n",
       "          [  3, 303, 302,  ..., 306, 305, 306]])])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_seq[0][0], edge_index_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index_seq[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 307, 2, 12]), torch.Size([2, 307]), torch.Size([2, 921]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_seq.shape, edge_index_seq[0].shape, edge_index_seq[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.8175,  0.6724,  1.0434,  ..., -0.9552,  0.8802,  0.2471],\n",
       "         [-0.8206,  0.2324,  0.9486,  ..., -0.9708,  0.7110,  0.4421],\n",
       "         [-0.8519,  0.3284,  0.9682,  ..., -0.6460,  0.9835,  0.1755],\n",
       "         ...,\n",
       "         [-1.1424,  0.5672,  1.1176,  ..., -1.2706,  0.5072,  0.9132],\n",
       "         [-0.7091,  0.6109,  1.1609,  ..., -1.4413,  0.9390,  0.6822],\n",
       "         [-0.9816,  0.7417,  1.0512,  ..., -1.3903,  0.6515,  0.8488]]],\n",
       "       grad_fn=<PermuteBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model( x_seq, edge_index_seq )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 307, 2, 12]), torch.Size([2, 307]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_seq.shape, edge_index_seq[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0862, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max( model( x_seq, edge_index_seq )-model( x_seq, edge_index_seq[0] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   7,   8,   9,  10,  11,  12,\n",
       "           13,  13,  14,  14,  14,  15,  15,  16,  17,  18,  19,  20,  21,  22,\n",
       "           22,  23,  23,  24,  24,  25,  26,  27,  27,  27,  27,  28,  28,  29,\n",
       "           30,  31,  32,  32,  33,  34,  34,  35,  35,  36,  36,  37,  38,  38,\n",
       "           39,  40,  41,  41,  42,  43,  44,  45,  45,  46,  47,  48,  48,  48,\n",
       "           49,  49,  50,  51,  52,  53,  53,  53,  54,  54,  55,  55,  56,  57,\n",
       "           58,  60,  61,  62,  62,  63,  64,  65,  65,  66,  66,  68,  69,  69,\n",
       "           70,  70,  71,  72,  74,  75,  75,  76,  76,  77,  77,  78,  79,  80,\n",
       "           81,  81,  83,  84,  84,  85,  86,  87,  88,  89,  90,  91,  91,  91,\n",
       "           93,  93,  94,  95,  95,  96,  99, 100, 101, 102, 105, 105, 106, 106,\n",
       "          107, 108, 108, 109, 110, 111, 113, 113, 114, 115, 116, 116, 118, 119,\n",
       "          120, 120, 121, 121, 121, 122, 123, 123, 124, 125, 127, 127, 128, 129,\n",
       "          129, 130, 131, 131, 132, 132, 132, 134, 137, 137, 139, 139, 142, 143,\n",
       "          144, 145, 146, 147, 148, 149, 150, 152, 156, 157, 157, 158, 159, 159,\n",
       "          160, 161, 164, 165, 166, 167, 169, 170, 171, 172, 173, 174, 175, 177,\n",
       "          178, 178, 179, 180, 181, 182, 184, 185, 188, 188, 189, 190, 191, 192,\n",
       "          192, 195, 196, 197, 201, 203, 205, 205, 206, 207, 208, 208, 209, 214,\n",
       "          215, 218, 219, 220, 221, 222, 223, 225, 226, 227, 229, 230, 231, 231,\n",
       "          232, 233, 234, 235, 236, 237, 238, 240, 242, 243, 244, 245, 247, 248,\n",
       "          249, 250, 251, 253, 254, 255, 256, 258, 259, 263, 265, 267, 269, 270,\n",
       "          272, 273, 274, 276, 277, 277, 278, 282, 283, 284, 286, 287, 288, 288,\n",
       "          289, 290, 292, 293, 294, 295, 296, 297, 300, 301, 302, 303, 305],\n",
       "         [  1, 106,   3,   4,   5,   6,  22, 174, 220,   9, 127,  67, 108, 291,\n",
       "          108, 151,  15, 104, 268,  16,  98,  17,  18, 174,  20,  21, 199,  97,\n",
       "          117, 220, 168,  25, 136, 161,  27,  28,  92, 111, 271,  29,  73, 223,\n",
       "           31,  38,  33, 141,  34,  35, 187,  42, 133,  94, 125,  41,  65, 281,\n",
       "           40,  41,  42, 219, 144,  44,  45,  46, 246,  47, 114, 269,  60, 275,\n",
       "          172, 112, 280, 280, 230,  54,  59,  75, 163,  67, 209,  97,  57,  58,\n",
       "           59, 103,  62, 166, 198,  64,  67, 303, 162, 125, 241, 301, 162, 210,\n",
       "           71, 204,  72,  73,  75,  82, 258,  77, 155,  78, 186, 294,  80, 136,\n",
       "          125, 126, 186,  85, 212,  86, 200,  88,  89,  90,  91, 114, 172, 203,\n",
       "          245, 298, 244,  96, 183,  97, 100, 213, 102, 120, 232, 193, 107, 232,\n",
       "          108, 281, 134, 110, 285, 149, 114, 135, 115, 116, 253, 163, 119, 144,\n",
       "          121, 154, 122, 140, 264, 123, 190, 202, 125, 257, 128, 176, 129, 130,\n",
       "          217, 179, 132, 279, 133, 153, 280, 138, 138, 266, 140, 224, 143, 144,\n",
       "          217, 146, 190, 201, 149, 161, 198, 153, 157, 158, 299, 234, 160, 200,\n",
       "          161, 213, 165, 243, 167, 168, 260, 171, 172, 199, 174, 175, 183, 178,\n",
       "          304, 194, 245, 209, 284, 183, 185, 186, 191, 262, 190, 234, 192, 193,\n",
       "          211, 196, 262, 198, 202, 304, 206, 216, 287, 224, 209, 252, 210, 215,\n",
       "          216, 219, 228, 285, 222, 223, 241, 272, 230, 228, 230, 231, 232, 239,\n",
       "          260, 234, 235, 236, 237, 238, 239, 241, 243, 244, 245, 281, 248, 249,\n",
       "          250, 251, 279, 254, 255, 299, 257, 261, 260, 264, 266, 268, 270, 271,\n",
       "          273, 274, 278, 296, 278, 291, 279, 283, 284, 301, 287, 288, 289, 306,\n",
       "          290, 291, 293, 294, 295, 296, 297, 298, 303, 302, 303, 304, 306]]),\n",
       " tensor([[  0,   0,   0,  ..., 299, 302, 304],\n",
       "         [  2,  14,   1,  ..., 301, 303, 306]]),\n",
       " tensor([[  0,   0,   0,  ..., 303, 303, 303],\n",
       "         [306,   2, 305,  ..., 304, 305, 306]]),\n",
       " tensor([[  0,   0,   0,  ..., 303, 303, 305],\n",
       "         [306,   2, 305,  ..., 305, 306, 306]]),\n",
       " tensor([[  0,   0,   0,  ..., 302, 303, 305],\n",
       "         [  3, 304,   5,  ..., 304, 304, 306]]),\n",
       " tensor([[  0,   0,   0,  ..., 302, 303, 305],\n",
       "         [306,   2, 305,  ..., 305, 306, 306]]),\n",
       " tensor([[  0,   0,   0,  ..., 304, 304, 305],\n",
       "         [  1, 306, 305,  ..., 305, 306, 306]]),\n",
       " tensor([[  0,   0,   0,  ..., 303, 304, 304],\n",
       "         [  2, 305,   3,  ..., 304, 305, 306]]),\n",
       " tensor([[  0,   0,   0,  ..., 302, 303, 305],\n",
       "         [  2, 305, 304,  ..., 305, 306, 306]]),\n",
       " tensor([[  0,   0,   0,  ..., 302, 303, 304],\n",
       "         [  1, 306, 305,  ..., 304, 306, 305]]),\n",
       " tensor([[  0,   0,   0,  ..., 303, 303, 304],\n",
       "         [  1, 306,   2,  ..., 305, 306, 305]]),\n",
       " tensor([[  0,   0,   0,  ..., 302, 303, 303],\n",
       "         [  3, 303, 302,  ..., 306, 305, 306]])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ i for i in edge_index_seq ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load cellular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Testing MSTGCN block with changing edge index over time.\n",
    "\"\"\"\n",
    "nb_time_strides = 1\n",
    "\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_for_predict = 4\n",
    "len_input = 12\n",
    "node_features = 3\n",
    "\n",
    "nb_block = 1\n",
    "K = 2\n",
    "nb_chev_filter = 2\n",
    "nb_time_filter = 2\n",
    "batch_size = 1\n",
    "\n",
    "model = MSTGCN( nb_block, node_features, K, nb_chev_filter,\n",
    "                nb_time_filter, nb_time_strides, \n",
    "                num_for_predict, len_input ).to(device)\n",
    "T = len_input\n",
    "\n",
    "node_count = 14585\n",
    "\n",
    "num_for_predict = 1\n",
    "len_input = 12\n",
    "nb_time_strides = 1\n",
    "\n",
    "node_features = 3\n",
    "nb_block = 2\n",
    "x_seq = torch.zeros([batch_size,node_count, node_features,T]).to(device)\n",
    "target_seq = torch.zeros([batch_size,node_count,T]).to(device)\n",
    "edge_index_seq = []\n",
    "\n",
    "source = '/media/storage_3/abiricz/Mobilcell/TimeIntervalGraphs/'\n",
    "files = np.array( sorted([ i for i in os.listdir(source) ]) )[:12]\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(T):\n",
    "        loaded = np.load( source+files[t] )\n",
    "        x = torch.LongTensor( loaded['data_x'] )\n",
    "        edge_index = torch.LongTensor( loaded['data_edge_index']  )\n",
    "        x_seq[b,:,:,t] = x.to(device)\n",
    "        #if b == 0:\n",
    "        edge_index_seq.append( edge_index.to(device) )\n",
    "        #target = create_mock_target(node_count, num_classes).to(device)\n",
    "        #target_seq[b,:,t] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 14585, 3, 12]), 12, torch.Size([2, 28863]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_seq.shape, len(edge_index_seq), edge_index_seq[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0630, 1.0753, 0.3691, 1.3912],\n",
       "         [0.0630, 1.0753, 0.3691, 1.3912],\n",
       "         [0.0630, 1.0753, 0.3691, 1.3912],\n",
       "         ...,\n",
       "         [0.0630, 1.0753, 0.3691, 1.3912],\n",
       "         [0.0630, 1.0753, 0.3691, 1.3912],\n",
       "         [0.0630, 1.0753, 0.3691, 1.3912]]], grad_fn=<PermuteBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model( x_seq, edge_index_seq )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = ASTGCN(nb_block, node_features, K, nb_chev_filter, nb_time_filter, nb_time_strides, num_for_predict, \n",
    "        len_input, node_count, normalization=None, bias=True).to(device)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model( x_seq, edge_index_seq )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
