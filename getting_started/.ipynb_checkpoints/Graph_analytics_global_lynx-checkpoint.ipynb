{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "import collections\n",
    "from random import choice\n",
    "import copy\n",
    "\n",
    "from graph_tool.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "threshold: 1, 2, 4, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Locate folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source = '/mnt/lynxkite/data/kite_data/upload/'\n",
    "source = '/mnt/processed_data/day_graphs_cleaned/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read all filenames and sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((365,),\n",
       " array(['output_20181201.csv.gz', 'output_20181202.csv.gz',\n",
       "        'output_20181203.csv.gz'], dtype='<U22'),\n",
       " array(['output_20191127.csv.gz', 'output_20191128.csv.gz',\n",
       "        'output_20191129.csv.gz', 'output_20191130.csv.gz'], dtype='<U22'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = sorted([ i for i in os.listdir(source) if '.csv.gz' in i ])\n",
    "files = np.array( sorted([ i for i in files if 'output_' in i ]) )\n",
    "files.shape, files[:3], files[-4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select the year 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2018.12.01-2019.11.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['output_20181201.csv.gz', 'output_20181202.csv.gz',\n",
       "        'output_20181203.csv.gz'], dtype='<U22'),\n",
       " array(['output_20191128.csv.gz', 'output_20191129.csv.gz',\n",
       "        'output_20191130.csv.gz'], dtype='<U22'),\n",
       " (365,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[:3], files[-3:], files.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>dst</th>\n",
       "      <th>traffic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>290500</td>\n",
       "      <td>282186</td>\n",
       "      <td>1.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>539818</td>\n",
       "      <td>541729</td>\n",
       "      <td>1.291901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>171554</td>\n",
       "      <td>175387</td>\n",
       "      <td>2.653278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>528854</td>\n",
       "      <td>531414</td>\n",
       "      <td>1.134900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>303912</td>\n",
       "      <td>289218</td>\n",
       "      <td>1.017857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      src     dst   traffic\n",
       "0  290500  282186  1.052632\n",
       "1  539818  541729  1.291901\n",
       "2  171554  175387  2.653278\n",
       "3  528854  531414  1.134900\n",
       "4  303912  289218  1.017857"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv( source+files[0], delimiter=',' )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(735332, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data to be able to parse it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([290500, 539818, 171554]),\n",
       " array([282186, 541729, 175387]),\n",
       " array([\"{'weight': 1.0526}\", \"{'weight': 1.2919}\", \"{'weight': 2.6533}\"],\n",
       "       dtype='<U19'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_part = df.src.values\n",
    "dst_part = df.dst.values\n",
    "weight_part = []\n",
    "for i in range( df.shape[0] ):\n",
    "    weight_part.append( '{\\'weight\\': '+str( np.round( df.traffic[i], 4 ) )[:7]+'}' )\n",
    "weight_part = np.array( weight_part )\n",
    "src_part[:3], dst_part[:3], weight_part[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "grap_to_parse = []\n",
    "for i in range( src_part.shape[0] ):\n",
    "     grap_to_parse.append( str(src_part[i]) + ' ' + str( dst_part[i]) +' ' + weight_part[i] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"290500 282186 {'weight': 1.0526}\",\n",
       " \"539818 541729 {'weight': 1.2919}\",\n",
       " \"171554 175387 {'weight': 2.6533}\",\n",
       " \"528854 531414 {'weight': 1.1349}\",\n",
       " \"303912 289218 {'weight': 1.0179}\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grap_to_parse[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation of graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.parse_edgelist( grap_to_parse , delimiter=' ', nodetype=int, create_using=nx.Graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if graph is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ i for i in nx.all_neighbors( G, 290500) ].index(282186)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automatization of this process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_day_graph_from_csv( path_to_file ):\n",
    "    df = pd.read_csv( path_to_file, delimiter=',' )\n",
    "    src_part = df.src.values\n",
    "    dst_part = df.dst.values\n",
    "    weight_part = []\n",
    "    \n",
    "    for i in range( df.shape[0] ):\n",
    "        weight_part.append( '{\\'weight\\': '+str( np.round( df.traffic[i], 4 ) )[:7]+'}' )\n",
    "    weight_part = np.array( weight_part )\n",
    "    \n",
    "    grap_to_parse = []\n",
    "    for i in range( src_part.shape[0] ):\n",
    "         grap_to_parse.append( str(src_part[i]) + ' ' + str( dst_part[i]) +' ' + weight_part[i] )\n",
    "            \n",
    "    G = nx.parse_edgelist( grap_to_parse , delimiter=' ', nodetype=int, create_using=nx.Graph())\n",
    "    # graph node id based on cell id\n",
    "    G_nodes_id = np.array( [i[0] for i in G.nodes(True) ] ).astype(int)\n",
    "    G_nodes_df = pd.read_csv( source+'../boxids_500.csv' ).iloc[ G_nodes_id ]\n",
    "    G_nodes_df_header = list( G_nodes_df )\n",
    "    G_nodes_id = G_nodes_df.values\n",
    "    \n",
    "    return G, G_nodes_id, G_nodes_df_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "G, G_nodes_id, G_nodes_df_header = create_day_graph_from_csv( source+files[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98214, 460521)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G.nodes), len(G.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.90500000e+05, 2.41194000e+05, 6.53591000e+05, 4.75146629e+01,\n",
       "        1.90951229e+01],\n",
       "       [2.82186000e+05, 2.37694000e+05, 6.47091000e+05, 4.74831838e+01,\n",
       "        1.90088470e+01]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_nodes_id[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['boxid', 'eovx', 'eovy', 'lat', 'lon']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_nodes_df_header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert nx graph to Graph-tool graph to get some processing speed increase\n",
    "\n",
    "https://bbengfort.github.io/snippets/2016/06/23/graph-tool-from-networkx.html (outdated)\n",
    "\n",
    "https://gist.github.com/tomshaffner/7a2df7f9ec6b1be33dd0413897125683 (updated, works with nx 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prop_type(value, key=None):\n",
    "    \"\"\"\n",
    "    Performs typing and value conversion for the graph_tool PropertyMap class.\n",
    "    If a key is provided, it also ensures the key is in a format that can be\n",
    "    used with the PropertyMap. Returns a tuple, (type name, value, key)\n",
    "    \"\"\"\n",
    "    if isinstance(key, str):\n",
    "        # Encode the key as utf-8\n",
    "        key = key.encode('utf-8', errors='replace')\n",
    "\n",
    "    # Deal with the value\n",
    "    if isinstance(value, bool):\n",
    "        tname = 'bool'\n",
    "\n",
    "    elif isinstance(value, int):\n",
    "        tname = 'float'\n",
    "        value = float(value)\n",
    "\n",
    "    elif isinstance(value, float):\n",
    "        tname = 'float'\n",
    "\n",
    "    elif isinstance(value, str):\n",
    "        tname = 'string'\n",
    "        value = value.encode('utf-8', errors='replace')\n",
    "\n",
    "    elif isinstance(value, dict):\n",
    "        tname = 'object'\n",
    "\n",
    "    else:\n",
    "        tname = 'string'\n",
    "        value = str(value)\n",
    "        \n",
    "    #If key is a byte value, decode it to string\n",
    "    try:\n",
    "        key = key.decode('utf-8')\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "    return tname, value, key\n",
    "\n",
    "\n",
    "def nx2gt(nxG):\n",
    "    \"\"\"\n",
    "    Converts a networkx graph to a graph-tool graph.\n",
    "    \"\"\"\n",
    "    # Phase 0: Create a directed or undirected graph-tool Graph\n",
    "    gtG = Graph(directed=nxG.is_directed())\n",
    "\n",
    "    # Add the Graph properties as \"internal properties\"\n",
    "    for key, value in list(nxG.graph.items()):\n",
    "        # Convert the value and key into a type for graph-tool\n",
    "        tname, value, key = get_prop_type(value, key)\n",
    "\n",
    "        prop = gtG.new_graph_property(tname) # Create the PropertyMap\n",
    "        \n",
    "        gtG.graph_properties[key] = prop     # Set the PropertyMap\n",
    "        gtG.graph_properties[key] = value    # Set the actual value\n",
    "\n",
    "    # Phase 1: Add the vertex and edge property maps\n",
    "    # Go through all nodes and edges and add seen properties\n",
    "    # Add the node properties first\n",
    "    nprops = set() # cache keys to only add properties once\n",
    "    for node, data in nxG.nodes(data=True):\n",
    "\n",
    "        # Go through all the properties if not seen and add them.\n",
    "        for key, val in list(data.items()):            \n",
    "            if key in nprops: continue # Skip properties already added\n",
    "\n",
    "            # Convert the value and key into a type for graph-tool\n",
    "            tname, _, key  = get_prop_type(val, key)\n",
    "\n",
    "            prop = gtG.new_vertex_property(tname) # Create the PropertyMap\n",
    "            gtG.vertex_properties[key] = prop     # Set the PropertyMap\n",
    "\n",
    "            # Add the key to the already seen properties\n",
    "            nprops.add(key)\n",
    "\n",
    "    # Also add the node id: in NetworkX a node can be any hashable type, but\n",
    "    # in graph-tool node are defined as indices. So we capture any strings\n",
    "    # in a special PropertyMap called 'id' -- modify as needed!\n",
    "    gtG.vertex_properties['id'] = gtG.new_vertex_property('string')\n",
    "\n",
    "    # Add the edge properties second\n",
    "    eprops = set() # cache keys to only add properties once\n",
    "    for src, dst, data in nxG.edges(data=True):\n",
    "\n",
    "        # Go through all the edge properties if not seen and add them.\n",
    "        for key, val in list(data.items()):            \n",
    "            if key in eprops: continue # Skip properties already added\n",
    "\n",
    "            # Convert the value and key into a type for graph-tool\n",
    "            tname, _, key = get_prop_type(val, key)\n",
    "            \n",
    "            prop = gtG.new_edge_property(tname) # Create the PropertyMap\n",
    "            gtG.edge_properties[key] = prop     # Set the PropertyMap\n",
    "\n",
    "            # Add the key to the already seen properties\n",
    "            eprops.add(key)\n",
    "\n",
    "    # Phase 2: Actually add all the nodes and vertices with their properties\n",
    "    # Add the nodes\n",
    "    vertices = {} # vertex mapping for tracking edges later\n",
    "    for node, data in nxG.nodes(data=True):\n",
    "\n",
    "        # Create the vertex and annotate for our edges later\n",
    "        v = gtG.add_vertex()\n",
    "        vertices[node] = v\n",
    "\n",
    "        # Set the vertex properties, not forgetting the id property\n",
    "        data['id'] = str(node)\n",
    "        for key, value in list(data.items()):\n",
    "            gtG.vp[key][v] = value # vp is short for vertex_properties\n",
    "\n",
    "    # Add the edges\n",
    "    for src, dst, data in nxG.edges(data=True):\n",
    "\n",
    "        # Look up the vertex structs from our vertices mapping and add edge.\n",
    "        e = gtG.add_edge(vertices[src], vertices[dst])\n",
    "\n",
    "        # Add the edge properties\n",
    "        for key, value in list(data.items()):\n",
    "            gtG.ep[key][e] = value # ep is short for edge_properties\n",
    "\n",
    "    # Done, finally!\n",
    "    return gtG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load graph from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read graph from csv file\n",
    "day_csv = pd.read_csv( source+files[0] )\n",
    "G, G_nodes_id, G_nodes_df_header = create_day_graph_from_csv( path_to_file=source+files[0] )\n",
    "# convert to Graph-tool graph object\n",
    "gtG = nx2gt(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph object, undirected, with 98214 vertices and 460521 edges, 1 internal vertex property, 1 internal edge property, at 0x7f0cb30ffeb8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<EdgePropertyMap object with value type 'double', for Graph 0x7f0cb30ffeb8, at 0x7f0cba9919b0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtG._Graph__edge_properties['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_edges': 460521}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{ 'num_edges': len(list(gtG._Graph__edge_properties['weight'])) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<VertexPropertyMap object with value type 'string', for Graph 0x7f0cb30ffeb8, at 0x7f0cf744b320>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtG._Graph__vertex_properties['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_vertices': 98214}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{ 'num_vertices': len(list(gtG._Graph__vertex_properties['id'])) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate random graph based on the configuration model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtG_rnd = copy.deepcopy(gtG)\n",
    "random_rewire( gtG_rnd, parallel_edges=True, self_loops=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics to be calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_num_vertices(g):\n",
    "    return { 'value': len(list(g._Graph__vertex_properties['id'])) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_num_edges(g):\n",
    "    return { 'value': len(list(g._Graph__edge_properties['weight'])) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_assortativity(g):\n",
    "    value, var = assortativity( g, 'total', eweight=g._Graph__edge_properties['weight'] )\n",
    "    return {'value': value, 'variance': var }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scalar_assortativity(g):\n",
    "    value, var = scalar_assortativity( g, 'total', eweight=g._Graph__edge_properties['weight'] )\n",
    "    return {'value': value, 'variance': var }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pseudo_diameter(g):\n",
    "    value, _ = pseudo_diameter(g, weights=g._Graph__edge_properties['weight'])\n",
    "    return {'value': int(value) }"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# runs very slow!\n",
    "def calculate_sum_of_max_cliques(g):\n",
    "    return sum(1 for c in max_cliques(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_min_spanning_tree(g):\n",
    "    return {'num_edges_involved': sum( list(min_spanning_tree(g, weights=g._Graph__edge_properties['weight'])) ) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vertex_percolation(g):\n",
    "    vertices = sorted( [v for v in g.vertices()], key=lambda v: v.out_degree() )\n",
    "    sizes, comp = vertex_percolation(g, vertices)\n",
    "    np.random.shuffle(vertices)\n",
    "    sizes2, comp = vertex_percolation(g, vertices)\n",
    "    fractions_remaining = np.array( [ 0.99, 0.9, 0.5, 0.3, 0.1, 0.01, 0.001 ] )\n",
    "    items_direct = {}\n",
    "    for i in fractions_remaining:\n",
    "        idx = np.argmax( (sizes/sizes[-1])[::-1] < i ) # where only fraction remaining\n",
    "        vert_frac_removed = idx / len(vertices)\n",
    "        items_direct[str(i)] = vert_frac_removed\n",
    "    items_random = {}\n",
    "    for i in fractions_remaining:\n",
    "        idx = np.argmax( (sizes2/sizes2[-1])[::-1] < i ) # where only fraction remaining\n",
    "        vert_frac_removed = idx / len(vertices)\n",
    "        items_random[str(i)] = vert_frac_removed\n",
    "    \n",
    "    return { 'directed': items_direct, 'random': items_random }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_edge_percolation(g):\n",
    "    edges = sorted([(e.source(), e.target()) for e in g.edges()],\n",
    "                   key=lambda e: e[0].out_degree() * e[1].out_degree())\n",
    "    sizes, comp = edge_percolation(g, edges)\n",
    "    np.random.shuffle(edges)\n",
    "    sizes2, comp = edge_percolation(g, edges)\n",
    "    fractions_remaining = np.array( [ 0.99, 0.9, 0.5, 0.3, 0.1, 0.01, 0.001 ] )\n",
    "    items_direct = {}\n",
    "    for i in fractions_remaining:\n",
    "        idx = np.argmax( (sizes/sizes[-1])[::-1] < i ) # where only fraction remaining\n",
    "        edge_frac_removed = idx / len(edges)\n",
    "        items_direct[str(i)] = edge_frac_removed\n",
    "    items_random = {}\n",
    "    for i in fractions_remaining:\n",
    "        idx = np.argmax( (sizes2/sizes2[-1])[::-1] < i ) # where only fraction remaining\n",
    "        edge_frac_removed = idx / len(edges)\n",
    "        items_random[str(i)] = edge_frac_removed\n",
    "    \n",
    "    return { 'directed': items_direct, 'random': items_random }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_global_clustering(g):\n",
    "    values, num_triangs, num_triples = global_clustering(g, weight=g._Graph__edge_properties['weight'], ret_counts=True)\n",
    "    return { 'value': values[0], 'std': values[1], \n",
    "             'number_of_triangs': int(num_triangs), 'number_of_triples': int(num_triples) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New calculations, tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'value': -0.0018567809410044496, 'variance': 0.00016557744031522688},\n",
       " {'value': 0.0005371268632893054, 'variance': 0.0002743402724337821})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_assortativity(gtG), calculate_assortativity(gtG_rnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'value': 0.3633888310742778, 'variance': 0.04259266080533669},\n",
       " {'value': -0.02527205164860106, 'variance': 0.015980774766955037})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_scalar_assortativity(gtG), calculate_scalar_assortativity(gtG_rnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'value': 422}, {'value': 2844})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_pseudo_diameter(gtG), calculate_pseudo_diameter(gtG_rnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'num_edges_involved': 98210}, {'num_edges_involved': 96130})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_min_spanning_tree(gtG), calculate_min_spanning_tree(gtG_rnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'directed': {'0.99': 0.00012218217362086872,\n",
       "   '0.9': 0.0006618201071130388,\n",
       "   '0.5': 0.008970207913332112,\n",
       "   '0.3': 0.017584051153603356,\n",
       "   '0.1': 0.027847353737756327,\n",
       "   '0.01': 0.050308509988392695,\n",
       "   '0.001': 0.06689474005742563},\n",
       "  'random': {'0.99': 0.0036349196652208445,\n",
       "   '0.9': 0.058596534099008286,\n",
       "   '0.5': 0.33893334962428984,\n",
       "   '0.3': 0.510222575192946,\n",
       "   '0.1': 0.730761398578614,\n",
       "   '0.01': 0.9171401225894475,\n",
       "   '0.001': 0.9711344614820697}},\n",
       " {'directed': {'0.99': 9.163663021565153e-05,\n",
       "   '0.9': 0.001690186735088684,\n",
       "   '0.5': 0.01871423625959639,\n",
       "   '0.3': 0.03375282546276498,\n",
       "   '0.1': 0.05184596900645529,\n",
       "   '0.01': 0.059176899423707414,\n",
       "   '0.001': 0.06644673875414911},\n",
       "  'random': {'0.99': 0.006058199442034741,\n",
       "   '0.9': 0.05976744659620828,\n",
       "   '0.5': 0.3370598896287698,\n",
       "   '0.3': 0.508114932697986,\n",
       "   '0.1': 0.7452705316960923,\n",
       "   '0.01': 0.9290936119086892,\n",
       "   '0.001': 0.982365039607388}})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_vertex_percolation(gtG), calculate_vertex_percolation(gtG_rnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'directed': {'0.99': 0.555800929816447,\n",
       "   '0.9': 0.6825074209428017,\n",
       "   '0.5': 0.8023521185787401,\n",
       "   '0.3': 0.8332844756265186,\n",
       "   '0.1': 0.8746615246644561,\n",
       "   '0.01': 0.9304049109595437,\n",
       "   '0.001': 0.9809780661468207},\n",
       "  'random': {'0.99': 0.01651173344972325,\n",
       "   '0.9': 0.1556541395506394,\n",
       "   '0.5': 0.6506891108114505,\n",
       "   '0.3': 0.8323160073047701,\n",
       "   '0.1': 0.9571007619630809,\n",
       "   '0.01': 0.9934508958331976,\n",
       "   '0.001': 0.9974572277920007}},\n",
       " {'directed': {'0.99': 0.6810851188110857,\n",
       "   '0.9': 0.7425546283448529,\n",
       "   '0.5': 0.8371583489135132,\n",
       "   '0.3': 0.8594070628700972,\n",
       "   '0.1': 0.8771391532633691,\n",
       "   '0.01': 0.8901722179878876,\n",
       "   '0.001': 0.9133633428225857},\n",
       "  'random': {'0.99': 0.015176289463455521,\n",
       "   '0.9': 0.14984767252742004,\n",
       "   '0.5': 0.6428089055656528,\n",
       "   '0.3': 0.8284877345441359,\n",
       "   '0.1': 0.9657301187133703,\n",
       "   '0.01': 0.9942955912976824,\n",
       "   '0.001': 0.9960414400211934}})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_edge_percolation(gtG), calculate_edge_percolation(gtG_rnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'value': 0.7658621097396574,\n",
       " 'std': 0.04466038167056891,\n",
       " 'number_of_triangs': 2033937768,\n",
       " 'number_of_triples': 7967247926}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_global_clustering(gtG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'value': 0.06007740540677145,\n",
       " 'std': 0.0023349111599151044,\n",
       " 'number_of_triangs': 69953168,\n",
       " 'number_of_triples': 3493151919}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_global_clustering(gtG_rnd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NOTE: For undirected graphs, the “out-degree” is synonym for degree, and in this case the in-degree of a vertex is always zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination = '/mnt/graph_analitics_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:59<00:00,  6.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n",
      "Already processed, skipping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for f in tqdm( range( files.shape[0] ) ):\n",
    "    # global metrics in json format!\n",
    "    savename = destination+'graph_global_attributes_'+files[f].split('.')[0][-8:]+'.json'\n",
    "    if not os.path.exists( savename ):\n",
    "\n",
    "        #read graph from csv file\n",
    "        day_csv = pd.read_csv( source+files[f] )\n",
    "        G, G_nodes_id, G_nodes_df_header = create_day_graph_from_csv( path_to_file=source+files[f] )\n",
    "        # convert to Graph-tool graph object\n",
    "        gtG = nx2gt(G)\n",
    "        # get random graph with configuration model\n",
    "        gtG_rnd = copy.deepcopy(gtG)\n",
    "        random_rewire( gtG_rnd, parallel_edges=True, self_loops=True )\n",
    "        \n",
    "        dict_to_dump = {} # every attribute will be written to this\n",
    "        \n",
    "        dict_to_dump['num_vertices_graph'] = calculate_num_vertices(gtG)\n",
    "        dict_to_dump['num_vertices_config'] = calculate_num_vertices(gtG_rnd)\n",
    "        \n",
    "        dict_to_dump['num_edges_graph'] = calculate_num_edges(gtG)\n",
    "        dict_to_dump['num_edges_config'] = calculate_num_edges(gtG_rnd)\n",
    "        \n",
    "        dict_to_dump['assortativity_graph'] = calculate_assortativity(gtG)\n",
    "        dict_to_dump['assortativity_config'] = calculate_assortativity(gtG_rnd)\n",
    "        \n",
    "        dict_to_dump['scalar_assortativity_graph'] = calculate_scalar_assortativity(gtG)\n",
    "        dict_to_dump['scalar_assortativity_config'] = calculate_scalar_assortativity(gtG_rnd)\n",
    "        \n",
    "        dict_to_dump['pseudo_diameter_graph'] = calculate_pseudo_diameter(gtG)\n",
    "        dict_to_dump['pseudo_diameter_config'] = calculate_pseudo_diameter(gtG_rnd)\n",
    "        \n",
    "        dict_to_dump['min_spanning_tree_graph'] = calculate_min_spanning_tree(gtG)\n",
    "        dict_to_dump['min_spanning_tree_config'] = calculate_min_spanning_tree(gtG_rnd)\n",
    "        \n",
    "        dict_to_dump['vertex_percolation_graph'] = calculate_vertex_percolation(gtG)\n",
    "        dict_to_dump['vertex_percolation_config'] = calculate_vertex_percolation(gtG_rnd)\n",
    "        \n",
    "        dict_to_dump['edge_percolation_graph'] = calculate_edge_percolation(gtG)\n",
    "        dict_to_dump['edge_percolation_config'] = calculate_edge_percolation(gtG_rnd)\n",
    "        \n",
    "        dict_to_dump['global_clustering_graph'] = calculate_global_clustering(gtG)\n",
    "        dict_to_dump['global_clustering_config'] = calculate_global_clustering(gtG_rnd)\n",
    "\n",
    "        with open(savename, 'w', encoding='utf-8') as f:\n",
    "            json.dump( dict_to_dump, f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "        #print(dict_to_dump)\n",
    "    else:\n",
    "        print('Already processed, skipping!') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
